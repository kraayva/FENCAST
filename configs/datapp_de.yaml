# configs/datapp_de.yaml

# General settings
setup_name: 'de_uvtzq_scf_NUTS2'

# Data Processing Settings
data_processing:
  drop_columns: ['DE50']

# Target data settings
time_start: '1980-01-01'
time_end: '2024-12-31'
target_data_raw: 'data/raw/cfr_NUTS2-DE.csv'
target_size: 37

# Feature data settings
input_size_flat: 20297
input_channels: 1 
era5_data_raw:
  u_component_of_wind: 'data/raw/era5_de_u_component_of_wind.nc'
  v_component_of_wind: 'data/raw/era5_de_v_component_of_wind.nc'
  temperature: 'data/raw/era5_de_temperature.nc'
  geopotential: 'data/raw/era5_de_geopotential.nc'
  specific_humidity: 'data/raw/era5_de_specific_humidity.nc'

feature_var_names:
  u_component_of_wind: 'u'
  v_component_of_wind: 'v'
  temperature: 't'
  geopotential: 'z'
  specific_humidity: 'q'

era5_dataset_url: 'gs://weatherbench2/datasets/era5/1959-2022-6h-1440x721.zarr'

feature_region:
  lat_min: 47.0
  lat_max: 55.0
  lon_min: 5.0
  lon_max: 15.0

feature_variables:
  u_component_of_wind: [850, 300]
  v_component_of_wind: [850, 300]
  temperature: [1000, 500]
  geopotential: [1000, 500]
  specific_humidity: [925, 700]

feature_level: [500, 850, 1000]

# Dataset splitting configuration
split_years:
  # All other years will be used for training
  validation: 
    - 2005
    - 2006
    - 2010
    - 2011
    - 2014
  test: 
    - 2018
    - 2019
    - 2020
    - 2021

# Cross Validation Configuration
cross_validation:
  k_folds: 5
  epochs: 30  # Typically fewer epochs than tuning since we're using pre-optimized hyperparameters
  validation_metric: 'mse_loss'  # Metric to use for fold comparison
  save_individual_models: true   # Save best model from each fold
  year_based_splitting: true     # Use year-based splits for temporal consistency


# Model architecture settings for final training
model:
  cnn:
  batch_sizes:
    training: 64
    evaluation: 256
    tuning: 64

# Hyperparameter Tuning Settings
tuning:
  # Hyperparameter will be tuned if a dict. Otherwise, fixed value is used.
  trials: 50
  epochs: 50
  
  activation_name: 'ELU'
  scheduler_name: 'ReduceLROnPlateau'
  scheduler_patience: 4
  scheduler_factor: 0.2

  weight_decay:
    type: float
    min: 1.0e-5
    max: 1.0e-2
    log_scale: true

  early_stopping_patience: 6

# CNN-specific hyperparameter
cnn_tuning:
  lr:
    type: float
    min: 1.0e-5
    max: 1.0e-3
    log_scale: true
  optimizer_name: 'AdamW'
  dropout_rate:
    type: float
    min: 0.01
    max: 0.2
    log_scale: true
  n_conv_layers:
    type: list
    values: [3, 5]
  filters:
    type: int
    min: 16
    max: 160
    step: 16
  kernel_size: 
    type: list
    values: [3, 4, 5]

# Feature Engineering Settings
features:
  temporal:
    day_of_year: true
  normalization:
    exclude_patterns: ['day_of_year'] # Patterns to exclude from normalization

# MLWP model output data:
mlwp_names: ['pangu', 'ifs']

# timedeltas for download
mlwp_timedeltas: 
  pangu: [3, 7, 11, 15, 19, 23, 27, 31, 35, 39]
  ifs: [4, 8, 12, 16, 20, 24, 28, 32, 36, 40]

# lead times indices for evaluation (make sure that these correspond to forecasting time 1d, 2d, ...)
mlwp_timedelta_idx: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
mlwp_timedelta_days: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
