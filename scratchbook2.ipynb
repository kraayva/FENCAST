{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcad0cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eee6aea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_global(config=\"global\"):\n",
    "    with open(f\"configs/{config}.yaml\", \"r\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "    \n",
    "cfg = load_global()\n",
    "cfm = load_global(config=\"datapp_de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8eb44515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load target dataset\n",
    "target_ds = pd.read_csv(cfm[\"target_data_raw\"])\n",
    "target_ds = target_ds[target_ds[\"Date\"].str.endswith(\"12:00:00\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc00d9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNRegionPool(nn.Module):\n",
    "    def __init__(self, n_in_ch=15, n_regions=38, H=32, W=40, hidden=64, head_hidden=64, W_region=None):\n",
    "        super().__init__()\n",
    "        self.H, self.W = H, W\n",
    "        assert W_region is not None, \"Provide region pooling matrix W_region [n_regions, H*W]\"\n",
    "        # Store as dense or sparse; einsum works with dense. Convert if needed.\n",
    "        if W_region.is_sparse:\n",
    "            W_region = W_region.to_dense()\n",
    "        self.register_buffer(\"W_region\", W_region)  # [R, L], not a parameter\n",
    "\n",
    "        # Lightweight CNN backbone\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv2d(n_in_ch, 32, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32), nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1, stride=2, bias=False),  # -> [64, 16, 20]\n",
    "            nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(64, hidden, kernel_size=3, padding=1, dilation=2, bias=False),\n",
    "            nn.BatchNorm2d(hidden), nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # Per-region head (shared weights across regions)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden, head_hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(head_hidden, 1),\n",
    "        )\n",
    "        # Optional: learn a small region bias\n",
    "        self.region_bias = nn.Parameter(torch.zeros(n_regions))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [B, C=15, H=32, W=40]\n",
    "        Returns: [B, n_regions]\n",
    "        \"\"\"\n",
    "        B = x.size(0)\n",
    "        feat = self.backbone(x)              # [B, hidden, H', W'] where H'=16, W'=20\n",
    "        H2, W2 = feat.shape[-2:]\n",
    "        feat = feat.view(B, feat.size(1), H2*W2)  # [B, hidden, L']\n",
    "        # If you downsampled, you also need a W for 16x20. Simplest: build W for 16x20 once.\n",
    "        # Below assumes W_region matches L' = H2*W2.\n",
    "        pooled = torch.einsum(\"rl,bcl->brc\", self.W_region, feat)  # [B, R, hidden]\n",
    "\n",
    "        # Apply shared MLP to each region vector\n",
    "        out = self.head(pooled)              # [B, R, 1]\n",
    "        out = out.squeeze(-1) + self.region_bias  # [B, R]\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96f5832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example placeholder (uniform weights over a toy mask):\n",
    "# indices: list of (region_id, flat_cell_id), values: area_fractions\n",
    "W = torch.sparse_coo_tensor(indices, values, size=(39, 16*20))  # match backbone output grid\n",
    "model = CNNRegionPool(n_in_ch=15, n_regions=39, H=32, W=40, hidden=64, head_hidden=64, W_region=W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3978e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = cfm[\"target_data_raw\"]\n",
    "df = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e4b0e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = df.columns.tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "839edcd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'regions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mregions\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'regions' is not defined"
     ]
    }
   ],
   "source": [
    "len(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf83204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\"data/processed/era5_de_u_component_of_wind.nc\")\n",
    "\n",
    "df = ds.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d20a8a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88375935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.read_parquet(\"data/processed/de_uvtzq_scf_NUTS2_features.parquet\")\n",
    "df_y = pd.read_parquet(\"data/processed/de_uvtzq_scf_NUTS2_labels.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e0b809e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "15341\n"
     ]
    }
   ],
   "source": [
    "print(np.isinf(df_X.values).sum())\n",
    "print(np.isinf(df_y.values).sum())\n",
    "\n",
    "print(np.isnan(df_X.values).sum())\n",
    "print(np.isnan(df_y.values).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9283637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y.to_parquet(\"data/processed/de_uvtzq_scf_NUTS2_labels.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
