{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a16f802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import yaml\n",
    "import numpy as np\n",
    "from itertools import zip_longest\n",
    "\n",
    "def load_global():\n",
    "    with open(\"configs/global.yaml\", \"r\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "    \n",
    "cfg = load_global()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36baf272",
   "metadata": {},
   "source": [
    "## Target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1a3d21dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = cfg[\"data_raw_dir\"] + \"/cfr_NUTS2-DE.csv\"\n",
    "df = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fc330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask: True if value is not NaN\n",
    "mask = df[\"DE11\"].notna()\n",
    "\n",
    "# Assign a group id: whenever a NaN occurs, the group number increases\n",
    "groups = mask.ne(mask.shift()).cumsum()\n",
    "\n",
    "# Filter only groups where values are numbers, then count their sizes\n",
    "lengths = df[mask].groupby(groups).size()\n",
    "\n",
    "# Calculate the average length\n",
    "average_length = lengths.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea642ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sequence length: 12.860486946318568\n"
     ]
    }
   ],
   "source": [
    "print(\"Average sequence length:\", average_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e16d6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.10664560958363106)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"DED5\"].fillna(0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "079b23c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for midnight and day\n",
    "df_day = df[df['Date'].str.endswith('12:00:00')].copy()\n",
    "df_day['Date'] = df_day['Date'].str[:-9]\n",
    "\n",
    "# filter for 1980 to 2024\n",
    "df_day = df_day[(df_day['Date'] >= '1980-01-01') & (df_day['Date'] <= '2024-12-31')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b20e294",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66634c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_era5 = xr.open_zarr('gs://weatherbench2/datasets/era5/1959-2023_01_10-wb13-6h-1440x721_with_derived_variables.zarr')\n",
    "ds_pangu = xr.open_zarr('gs://weatherbench2/datasets/pangu/2018-2022_0012_0p25.zarr')\n",
    "ds_neuralgcm = xr.open_zarr('gs://weatherbench2/datasets/neuralgcm_deterministic/2020-512x256.zarr')\n",
    "ds_graphcast = xr.open_zarr('gs://weatherbench2/datasets/graphcast/2020/date_range_2019-11-16_2021-02-01_12_hours_derived.zarr')\n",
    "ds_era5_hour = xr.open_zarr('gs://weatherbench2/datasets/era5/1959-2023_01_10-full_37-1h-0p25deg-chunk-1.zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9ae9f618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Variables present in\n",
      "All datasets           All but neuralgcm     \n",
      "--------------------------------------------\n",
      "geopotential           10m_u_component_of_wind\n",
      "specific_humidity      10m_v_component_of_wind\n",
      "temperature            10m_wind_speed\n",
      "u_component_of_wind    2m_temperature\n",
      "v_component_of_wind    geopotential\n",
      "wind_speed             mean_sea_level_pressure\n",
      "                       specific_humidity\n",
      "                       temperature\n",
      "                       u_component_of_wind\n",
      "                       v_component_of_wind\n",
      "                       wind_speed\n"
     ]
    }
   ],
   "source": [
    "# Check which variables are in all datasets\n",
    "valid_variables1 = [v for v in ds_era5.data_vars if \n",
    "                   #v in ds_era5_hour.data_vars and\n",
    "                   v in ds_pangu.data_vars and \n",
    "                   v in ds_neuralgcm.data_vars and \n",
    "                   v in ds_graphcast.data_vars]\n",
    "\n",
    "valid_variables2 = [v for v in ds_pangu.data_vars if \n",
    "                   v in ds_era5.data_vars and \n",
    "                   #v in ds_era5_hour.data_vars and\n",
    "                   #v in ds_neuralgcm.data_vars and \n",
    "                   v in ds_graphcast.data_vars]\n",
    "print(\"          Variables present in\")\n",
    "print(f\"{\"All datasets\":<{22}} {\"All but neuralgcm\":<{22}}\")\n",
    "print(\"-\" * (22 + 22))\n",
    "for a, b in zip_longest(valid_variables1, valid_variables2, fillvalue=\"\"):\n",
    "    print(f\"{a:<22} {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3f27e663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10m_u_component_of_wind',\n",
       " '10m_v_component_of_wind',\n",
       " '2m_dewpoint_temperature',\n",
       " '2m_temperature',\n",
       " 'angle_of_sub_gridscale_orography',\n",
       " 'anisotropy_of_sub_gridscale_orography',\n",
       " 'boundary_layer_height',\n",
       " 'geopotential',\n",
       " 'geopotential_at_surface',\n",
       " 'high_vegetation_cover',\n",
       " 'lake_cover',\n",
       " 'land_sea_mask',\n",
       " 'leaf_area_index_high_vegetation',\n",
       " 'leaf_area_index_low_vegetation',\n",
       " 'low_vegetation_cover',\n",
       " 'mean_sea_level_pressure',\n",
       " 'mean_surface_latent_heat_flux',\n",
       " 'mean_surface_net_long_wave_radiation_flux',\n",
       " 'mean_surface_net_short_wave_radiation_flux',\n",
       " 'mean_surface_sensible_heat_flux',\n",
       " 'mean_top_downward_short_wave_radiation_flux',\n",
       " 'mean_top_net_long_wave_radiation_flux',\n",
       " 'mean_top_net_short_wave_radiation_flux',\n",
       " 'mean_vertically_integrated_moisture_divergence',\n",
       " 'potential_vorticity',\n",
       " 'sea_ice_cover',\n",
       " 'sea_surface_temperature',\n",
       " 'slope_of_sub_gridscale_orography',\n",
       " 'snow_depth',\n",
       " 'soil_type',\n",
       " 'specific_humidity',\n",
       " 'standard_deviation_of_filtered_subgrid_orography',\n",
       " 'standard_deviation_of_orography',\n",
       " 'surface_pressure',\n",
       " 'temperature',\n",
       " 'total_cloud_cover',\n",
       " 'total_column_water',\n",
       " 'total_column_water_vapour',\n",
       " 'total_precipitation',\n",
       " 'type_of_high_vegetation',\n",
       " 'type_of_low_vegetation',\n",
       " 'u_component_of_wind',\n",
       " 'v_component_of_wind',\n",
       " 'vertical_velocity',\n",
       " 'volumetric_soil_water_layer_1',\n",
       " 'volumetric_soil_water_layer_2',\n",
       " 'volumetric_soil_water_layer_3',\n",
       " 'volumetric_soil_water_layer_4']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v for v in ds_era5_hour.data_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "82614d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Time</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Lev</th>\n",
       "      <th>Lead Time</th>\n",
       "      <th>Time Res/h</th>\n",
       "      <th>Lead Time Res/h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ERA5</td>\n",
       "      <td>93544</td>\n",
       "      <td>721</td>\n",
       "      <td>1440</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[6]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ERA5 1h</td>\n",
       "      <td>561264</td>\n",
       "      <td>721</td>\n",
       "      <td>1440</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pangu</td>\n",
       "      <td>3652</td>\n",
       "      <td>721</td>\n",
       "      <td>1440</td>\n",
       "      <td>13</td>\n",
       "      <td>40.0</td>\n",
       "      <td>[12]</td>\n",
       "      <td>[6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralGCM</td>\n",
       "      <td>797</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>37</td>\n",
       "      <td>31.0</td>\n",
       "      <td>[12]</td>\n",
       "      <td>[12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GraphCast</td>\n",
       "      <td>886</td>\n",
       "      <td>721</td>\n",
       "      <td>1440</td>\n",
       "      <td>37</td>\n",
       "      <td>40.0</td>\n",
       "      <td>[12]</td>\n",
       "      <td>[6]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset    Time  Lat   Lon  Lev  Lead Time Time Res/h Lead Time Res/h\n",
       "0       ERA5   93544  721  1440   13        NaN        [6]             NaN\n",
       "1    ERA5 1h  561264  721  1440   37        NaN        [1]             NaN\n",
       "2      Pangu    3652  721  1440   13       40.0       [12]             [6]\n",
       "3  NeuralGCM     797  256   512   37       31.0       [12]            [12]\n",
       "4  GraphCast     886  721  1440   37       40.0       [12]             [6]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check dimensions and resolution of datasets\n",
    "\n",
    "datasets = {\n",
    "    \"ERA5\": ds_era5,\n",
    "    \"ERA5 1h\": ds_era5_hour,\n",
    "    \"Pangu\": ds_pangu,\n",
    "    \"NeuralGCM\": ds_neuralgcm,\n",
    "    \"GraphCast\": ds_graphcast,\n",
    "}\n",
    "\n",
    "# Collect info about dimensions per dataset\n",
    "rows = []\n",
    "for name, ds in datasets.items():\n",
    "    dims = ds.sizes  # dict: {dim_name: size}\n",
    "    # Try to find matching dims; if missing -> set to None\n",
    "    time = dims.get(\"time\") or dims.get(\"times\") or None\n",
    "    lat = dims.get(\"lat\") or dims.get(\"latitude\") or None\n",
    "    lon = dims.get(\"lon\") or dims.get(\"longitude\") or None\n",
    "    lev = dims.get(\"level\") or dims.get(\"lev\") or dims.get(\"plev\") or None\n",
    "    lead = dims.get(\"prediction_timedelta\") or dims.get(\"lead\") or None\n",
    "\n",
    "    rows.append([name, time, lat, lon, lev, lead])\n",
    "\n",
    "# Create DataFrame\n",
    "df_dims = pd.DataFrame(rows, columns=[\"Dataset\", \"Time\", \"Lat\", \"Lon\", \"Lev\", \"Lead Time\"])\n",
    "\n",
    "# find time resolutions\n",
    "for name, ds in datasets.items():\n",
    "    time = ds.coords.get(\"time\")\n",
    "    if time is not None:\n",
    "        deltas = np.diff(time.values)  # differences between consecutive times\n",
    "        unique_deltas = np.unique(deltas)\n",
    "\n",
    "        #from ns to hours\n",
    "        unique_deltas = [int(delta / np.timedelta64(1, 'h')) for delta in unique_deltas]\n",
    "        df_dims.loc[df_dims[\"Dataset\"] == name, \"Time Res/h\"] = str(unique_deltas)\n",
    "\n",
    "    lead = ds.coords.get(\"prediction_timedelta\")\n",
    "    if lead is not None:\n",
    "        deltas = np.diff(lead.values)  # differences between consecutive lead times\n",
    "        unique_deltas = np.unique(deltas)\n",
    "\n",
    "        #from ns to hours\n",
    "        unique_deltas = [int(delta / np.timedelta64(1, 'h')) for delta in unique_deltas]\n",
    "        df_dims.loc[df_dims[\"Dataset\"] == name, \"Lead Time Res/h\"] = str(unique_deltas)\n",
    " \n",
    "\n",
    "df_dims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "dafa7314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.845405\n",
      "9.845405\n"
     ]
    }
   ],
   "source": [
    "print(ds_era5[\"wind_speed\"].sel(level=850).isel(time=0).sel(latitude=30, longitude=0).values)\n",
    "u = ds_era5[\"u_component_of_wind\"].sel(level=850).isel(time=0).sel(latitude=30, longitude=0).values\n",
    "v = ds_era5[\"v_component_of_wind\"].sel(level=850).isel(time=0).sel(latitude=30, longitude=0).values\n",
    "print(np.sqrt(u**2 + v**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7900f558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut out Germany from hourly ERA5 data\n",
    "ds_era5_hour_de = ds_era5_hour.sel(latitude=slice(55, 47), longitude=slice(5, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5ca0b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
